{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de precios de propiedades en Colombia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook implementa el análisis de los datos disponibles en Kaggle \"Colombia Housing Properties Price\" disponibles en el sitio de Kaggle:\n",
    "\n",
    "https://www.kaggle.com/julianusugaortiz/colombia-housing-properties-price/download\n",
    "\n",
    "<img src=\"dataset-cover.jpg\" width=\"1000\" height=\"400\">\n",
    "\n",
    "El dataset incluye precios reales de propiedades inmobiliarias en colombia. Para tener disponible nuestro dataset usaremos\n",
    "la librería kaggle que nos permite descargar los dataset de Kaggle. Tenga en cuenta que para esto necesitará suministrar un token de autorización para el ingreso a su cuenta, descargándolo de kaggle y ubicándolo en el directorio de instalación de su paquete kaggle. Sin embargo, si este método no funciona para usted, puede intentar cargar manualmente el archivo \"co_properties.csv\" descargado del enlace anterior, y adjunto al presente proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizamos el dataset para tener una idea general de la información que contiene:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ad_type</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>created_on</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "      <th>l4</th>\n",
       "      <th>l5</th>\n",
       "      <th>l6</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>surface_total</th>\n",
       "      <th>surface_covered</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>price_period</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>property_type</th>\n",
       "      <th>operation_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z5GURF86+s3KVdbvKdx4dQ==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>6.287127</td>\n",
       "      <td>-75.336540</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000e+07</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sevende Finca en Chaparrel de San Visent</td>\n",
       "      <td>sevende  finca mas 9 lotes en san visente  vereda chaparral a 2 kilometos de la8 parimentada  lotes des de 90 millones en adelante con escrituras con sus es planadiones al gunos tienen agua propia ven iescoje eltullo</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EbOqfrqoJKUuVFzkBymDgA==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>6.287127</td>\n",
       "      <td>-75.336540</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.500000e+08</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sevende Finca en San Visente An Tioquia 14  etaresa</td>\n",
       "      <td>sevende finca en san visente aprosimada mente 14 etareas con casa lus agua de acueduto y aguas propias con carretera sepiden 450 millones</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4et4/CQ6/jiiA31QcGbBSQ==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.600000e+09</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Venta de Lote Vereda Puente Pelaez El Retiro _ wasi1567707</td>\n",
       "      <td>Lote de 145.336 metros, topografia quebrada, con nacimiento de agua, Lote ubicado en la Vereda Puente Pelaez a solo 15 minutos del parque principal de El Retiro. Precio $ 0  POSIBILIDAD DE VENTA DE MENOR AREA.</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DnzyLOD2CU/exv0dQhVS/A==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>6.291447</td>\n",
       "      <td>-75.338812</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.500000e+07</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lote/terreno de 7000 mts2 nacimiento de agua San Vicente Antioquia</td>\n",
       "      <td>DESCRIPCION\\n\\nEspectacular oportunidad de negocio, para invertir o hacer una casa de recreo, fácil acceso para luz, agua y licencia de construccion.\\n\\nntra cualquier carro, a solo 10 minutos de San Vicente Antioquia y una hora y 10 minutos de Medellín, se pueden sacar dos banqueos, papeles al día, vista privilegiada al pueblo y 360%. \\n\\nEn este momento está en bosque y solo entra carro hasta donde empieza el lote, tiene un nacimiento de agua y pasa un arrollo por un lado, la zona es muy segura y de facil acceso.\\n\\nPara mas informacion 31161519y46 Alberto</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pg12IF9sRDSCcWZU6L2yig==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>3.457576</td>\n",
       "      <td>-76.558938</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Valle del Cauca</td>\n",
       "      <td>Cali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.700000e+08</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322.4 Venta de Lote en Aguacatal, Oeste de Cali</td>\n",
       "      <td>EXCELENTE OPORTUNIDAD PARA INVERSIÓN.\\n\\nVenta de Lote de 1200 m2 en El Aguacatal.\\n\\nCuenta con excelente ubicación, cerca del Colegio de la Presentación, excelente vista, zonas residenciales, paradas de transporte público, miradores y vías principales.</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>uh8DiLbc3HN7vTeT593MjQ==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>3.448069</td>\n",
       "      <td>-76.539430</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Valle del Cauca</td>\n",
       "      <td>Cali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.700000e+08</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1339.4 Venta de Lote Esquinero en San Antonio, Oeste de  Cali</td>\n",
       "      <td>¡Excelente oportunidad de negocio!\\n\\nVenta de Lote de 240 mts2 en vehicular en San Antonio, Cali Valle del Cauca.\\n\\nSe encuentra central en la ciudad de alta valorización, sobre una avenida principal en un sector turístico cultural muy reconocido de la ciudad, cerca de iglesia y del parque San Antonio, hoteles, restaurantes, paradas de transporte, centros comerciales, entre otros.\\n\\nValor negociable.</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vTQjNBLvIxPnkiUA20VS2A==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>Bello</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.300000e+08</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Se vende lote</td>\n",
       "      <td>Se vende lote entre machado y Copacabana muy bn ubicado dentra carro y moto excelente vista agua propia para hacer lago tiene 3 metros de ancho por 30 de fondo precio negociable.</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vNaJJcfDYZ32UD+a0EZpeg==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>6.338954</td>\n",
       "      <td>-75.541284</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>Bello</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.620000e+08</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Venta de apartamento en obra gris Niquia Bello</td>\n",
       "      <td>Cerca a: supermercados cercanos como el Éxito y Consumo, centro comercial puerta del norte, unidad deportiva Tulio Ospina, Clinica del Norte, Clinica especializada EMMSA, ademas de iglesias, centros educativos y universidades.\\n\\nCuenta con un área de 36 mts ubicado en un decimo piso, distribuido en un habitacion amplia, un baño, cocina, sala, balcón amplio y parqueadero de motos.\\n\\nLa copropiedad cuenta con piscina para adultos y niños, juegos infantiles, salón social, gimnasio, sauna y turco.\\n\\nInmobiliaria ZAR S.A.S</td>\n",
       "      <td>Apartamento</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EkYs7qj9WQGwEqFU4+ZTzQ==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>4.862854</td>\n",
       "      <td>-74.019871</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Cundinamarca</td>\n",
       "      <td>Chía</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.400000e+08</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VENDO LOTE YERBABUENA OPORTUNIDAD</td>\n",
       "      <td>Oportunidad ,Lote altos de Yerbabuena Chia, a 10 min de la autopista , uso residencial.\\n</td>\n",
       "      <td>Lote</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RXziFFL8sN/VBTalYMqLIA==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2.954532</td>\n",
       "      <td>-75.288075</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Huila</td>\n",
       "      <td>Neiva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000e+08</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VENTA DE LOTE EN LA JAGUA  NEIVA SimiCRM640583</td>\n",
       "      <td>640-583 ESPECTACULAR LOTE CON EXCELENTE UBICACIÓN  Se vende espectacular lote  excelente ubicación, zona  de gran proyección en la vía Fortalecillas a 15 minutos  de Neiva, sobre la  vía principal, vía pavimentada, en la vereda La Mata con un área de 40.000 m2, cuenta con servicios de acueducto, servicio de energía para su respectiva conexión, aljibe para  construcción.  Valor 20.000 por M2.</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>O+qJuKxNnWgZwNuovMr+Pw==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>9999-12-31</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>4.848700</td>\n",
       "      <td>-73.993607</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Cundinamarca</td>\n",
       "      <td>Sopó</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000e+08</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VENDO LOTE SOPO CONDOMINIO OPORTUNIDAD</td>\n",
       "      <td>Oportunidad ,Lote Aposentos de  Yerbabuena Sopo, estrato 1, Agua y Luz, condominio con Club House y Piscina, lote 2.050 mtrs construccion permitida 15%,  uso residencial. planta de tratamiento de aguas.\\n</td>\n",
       "      <td>Lote</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P9CM9Wb+xLohKrsaLO+m5g==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>6.165914</td>\n",
       "      <td>-75.609995</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>Itagui</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.700000e+10</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Venta de Bodega Autopista Sur Itagui _ wasi1595908</td>\n",
       "      <td>Excelente bodega en Itagui sector Industrial, sobre la autopista sur, area de lote 6549, area bloque 1 1587 area bloque 2 2192 area total 3779. PRECIO $ 00</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>uYyyDg7+LqpO2u2oJfgSgw==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2.205349</td>\n",
       "      <td>-75.621803</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Huila</td>\n",
       "      <td>Garzón</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000e+07</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VENTA DE LOTE EN VEREDA MAJO  GARZON SimiCRM640569</td>\n",
       "      <td>640-569 Ofertamos 23 lotes de terreno en sector semi-urbano cada uno con un área de 2.000 m2, costo de venta por metro cuadrado de  40.000.oo, ubicado a orillas de la vía central a tan solo 8 kilómetros de garzón hacia Neiva, ideal para la construcción de casas campestres, vías de acceso demarcadas y servicios públicos de agua y luz.</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eycgPpiVO2gDj1JGYl75gA==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>6.158352</td>\n",
       "      <td>-75.516371</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>Envigado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.400000e+08</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Venta de Lote Alto de las Palmas Envigado _ wasi1961890</td>\n",
       "      <td>Lote en exclusiva parcelacion de 1.555 metros, ubicado en El Alto de las Palmas cerca del Mall Indiana y antes del peaje al aeropuerto, excelentes vias de accesoio y servicios, exclusivo sector. Admon 480.000 Precio 740 millones.Hermosa y exclusiva parcelacion con Jacuzzy, sendero de trote y juegos infantiles.</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SGYi4fA0sB/AlcFlbMtyhA==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>6.162188</td>\n",
       "      <td>-75.503025</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>Envigado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.500000e+08</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Venta de lote Alto de las Palmas Envigado _ wasi1529071</td>\n",
       "      <td>Lote en excelente parcelacion de 1200 metros, completamente plano y con tres frentes, ubicado en El Alto de las Palmas cerca del Mall Indiana y al peaje, excelentes vias de accesoio y servicios. Admon $ 390.000 Predial $ Precio $                      Carlos Borja Propiedad Raiz            www . .propiedadraizcarlosborja. Com</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KJ3i73cxGWn8UTZnBh8srA==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>6.156342</td>\n",
       "      <td>-75.534353</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>Envigado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.100000e+09</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Venta de lote Alto de las Palmas Envigado _ wasi1529260</td>\n",
       "      <td>Lote en exclusiva parcelacion de 2.364 metros, ubicado en El Alto de las Palmas cerca del Mall Indiana, excelentes vias de accesoio y servicios, exclusivo sector. Admon $ 483.000 Predial $ 335.000 Precio $ 0 Unico Precio.                        Hermosa y exclusiva parcelacion con piscina de nado, gimnasio dotado, salon social, cancha de squash y cacha polideportiva.                        Carlos Borja Propiedad Raiz</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ep/QhYBmi7WGite+R4KHAQ==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>3.229000</td>\n",
       "      <td>-76.582000</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Valle del Cauca</td>\n",
       "      <td>Jamundí</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000e+08</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lote En Venta En Jamundi Haciendas De Potrerito CodVBVLZ_1972</td>\n",
       "      <td>VENDO.. VENDO.. En Excelente ubicación.,  Lote.. y Totalmente Plano. ubicado al ingreso del condominio.,  en la parte baja.. Cerca a la zona social del condominio.,  en haciendas de Potrerito. la mejor inversión. sector de alta valorización..  construya la vivienda de sus sueños. a su gusto..en el mejor sector y roseado de naturaleza.. excelente ubicación..  muy campestre..  tranquilidad.. el lote ya cuenta con todos sus servicios. tiene acueducto  propio. y subestación electrtiica propia.y Gases.. vías de  acceso pavimentadas  a sólo treinta minutos de Cali y a quince minutos de Alfaguara. donde encontrará supermercados..  el valor de la administración incluye el servicio de agua..ademas ya cuenta con piscinas.. canchas de tenía. lagos. Iglesia. salón social. unidad social. Completa..  documentos al día..  más información con INDIRA OYOLA CEL.  0..</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>YUjvRxYtLRAdc4bE5GWZxg==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>6.129631</td>\n",
       "      <td>-75.411701</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>Rionegro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.250000e+08</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Venta de lote en Rionegro Llano Grande _ wasi1535646</td>\n",
       "      <td>Hermoso Lote en exclusiva parcelacion de 1691 metros, ubicado en Llano Grande, cerca del Club Llano grande y Mall Llano grande. Admon $ 350.000 Predial $ 2.600.000 Año Precio $                      Carlos Borja Propiedad Raiz</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5RhpKq8BfQWTCJKgfFE0wA==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>6.177867</td>\n",
       "      <td>-75.443201</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>Rionegro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.500000e+08</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Venta de Lote Vereda San Ignacio Guarne _ wasi1567793</td>\n",
       "      <td>Lote de 10.133 metros, Esquinero, completamente plano, con luz, agua, sobre via principal, excelentes vias de acceso, uso comercial y servicio. Excelente Precio $ .  Precio de Oportunidad. Se ofrece otro lote de area similar, topografia quebrada y con hermosa vista. Lote de uso Mixto ubicado sobre la viia que de Santa Elena conduce a la glorieta de Sajonia, vereda San Ignasio, a 3 kilometros del intercambio vial donde estara el nuevo tunel,.</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>qTBsWD1KeFcXzs909obsPQ==</td>\n",
       "      <td>Propiedad</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>6.217268</td>\n",
       "      <td>-75.567956</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Antioquia</td>\n",
       "      <td>Medellín</td>\n",
       "      <td>El Poblado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+09</td>\n",
       "      <td>COP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Venta de Lote Castropol El Poblado Medellin _ wasi2396671</td>\n",
       "      <td>Lote de 796 metros, ubicado en Castropol a una cuadra de la Avenida El Poblado. con norma para construccion de 10 pisos mas sotanos de parqueos mas local. apartamento por piso mas terraza.Excelente ubicacion cerca del Centro Automotriz, excelente sector residencial.</td>\n",
       "      <td>Otro</td>\n",
       "      <td>Venta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import kaggle\n",
    "from zipfile import ZipFile\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def displaydf(df):\n",
    "    display(HTML(df.to_html())) \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "destiny = os.path.join(os.path.expanduser('~'),'Documents\\Properties_price\\data')\n",
    "if not os.path.exists(destiny):\n",
    "    os.mkdir(destiny)\n",
    "    \n",
    "path_file = os.path.join(os.path.expanduser('~'), 'Documents\\Properties_price\\data\\colombia-housing-properties-price.zip')\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "api.dataset_download_files('julianusugaortiz/colombia-housing-properties-price',path=destiny)\n",
    "\n",
    "with ZipFile(path_file, 'r') as zipObj:\n",
    "    zipObj.extractall(destiny)\n",
    "\n",
    "if os.path.exists(path_file):\n",
    "    os.remove(path_file)\n",
    "else:\n",
    "    print(\"The file zip does not exist\")\n",
    "\n",
    "path_file = os.path.join(os.path.expanduser('~'), 'Documents\\Properties_price\\data\\co_properties.csv')\n",
    "df = pd.read_csv(path_file, encoding='utf8')\n",
    "print(\"Visualizamos el dataset para tener una idea general de la información que contiene:\\n\")\n",
    "displaydf(df.iloc[0:20,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset contiene 1000000 filas y 25 columnas\n",
      "\n",
      "Los nombres de columnas en el data set son:\n",
      " ['id', 'ad_type', 'start_date', 'end_date', 'created_on', 'lat', 'lon', 'l1', 'l2', 'l3', 'l4', 'l5', 'l6', 'rooms', 'bedrooms', 'bathrooms', 'surface_total', 'surface_covered', 'price', 'currency', 'price_period', 'title', 'description', 'property_type', 'operation_type']\n",
      "\n",
      "Este dataset contiene información para los siguientes tipos de propiedades:\n",
      " ['Otro' 'Apartamento' 'Lote' 'Oficina' 'Local comercial' 'Casa' 'Finca'\n",
      " 'Depósito' 'Parqueadero' 'PH']\n",
      "\n",
      "Esta es una descripción general de las variables numéricas contenidas en el dataset:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>surface_total</th>\n",
       "      <th>surface_covered</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>838824.000000</td>\n",
       "      <td>838824.000000</td>\n",
       "      <td>189968.000000</td>\n",
       "      <td>273655.000000</td>\n",
       "      <td>827253.000000</td>\n",
       "      <td>152765.000000</td>\n",
       "      <td>1.591200e+05</td>\n",
       "      <td>9.948770e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.967509</td>\n",
       "      <td>-74.948342</td>\n",
       "      <td>3.121094</td>\n",
       "      <td>2.687698</td>\n",
       "      <td>2.477456</td>\n",
       "      <td>996.887932</td>\n",
       "      <td>2.488659e+03</td>\n",
       "      <td>4.509809e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.264294</td>\n",
       "      <td>1.076494</td>\n",
       "      <td>1.703937</td>\n",
       "      <td>14.270783</td>\n",
       "      <td>1.444242</td>\n",
       "      <td>6895.087600</td>\n",
       "      <td>3.618313e+05</td>\n",
       "      <td>2.123343e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.205429</td>\n",
       "      <td>-81.730319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-36.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.662609</td>\n",
       "      <td>-75.598128</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>6.500000e+01</td>\n",
       "      <td>2.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.059179</td>\n",
       "      <td>-75.442675</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.650000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.339000</td>\n",
       "      <td>-74.066938</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>1.830000e+02</td>\n",
       "      <td>4.200000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.354000</td>\n",
       "      <td>-67.482570</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>6820.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>1.323000e+08</td>\n",
       "      <td>8.500000e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lat            lon          rooms       bedrooms  \\\n",
       "count  838824.000000  838824.000000  189968.000000  273655.000000   \n",
       "mean        5.967509     -74.948342       3.121094       2.687698   \n",
       "std         2.264294       1.076494       1.703937      14.270783   \n",
       "min        -4.205429     -81.730319       1.000000       0.000000   \n",
       "25%         4.662609     -75.598128       2.000000       2.000000   \n",
       "50%         5.059179     -75.442675       3.000000       3.000000   \n",
       "75%         6.339000     -74.066938       3.000000       3.000000   \n",
       "max        13.354000     -67.482570      40.000000    6820.000000   \n",
       "\n",
       "           bathrooms  surface_total  surface_covered         price  \n",
       "count  827253.000000  152765.000000     1.591200e+05  9.948770e+05  \n",
       "mean        2.477456     996.887932     2.488659e+03  4.509809e+08  \n",
       "std         1.444242    6895.087600     3.618313e+05  2.123343e+09  \n",
       "min         1.000000     -36.000000     1.000000e+00  0.000000e+00  \n",
       "25%         2.000000      66.000000     6.500000e+01  2.000000e+06  \n",
       "50%         2.000000     100.000000     1.000000e+02  1.650000e+08  \n",
       "75%         3.000000     210.000000     1.830000e+02  4.200000e+08  \n",
       "max        20.000000  200000.000000     1.323000e+08  8.500000e+11  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"El dataset contiene {} filas y {} columnas\\n\".format(df.shape[0],df.shape[1]))\n",
    "print(\"Los nombres de columnas en el data set son:\\n {}\\n\".format(list(df.columns)))\n",
    "print(\"Este dataset contiene información para los siguientes tipos de propiedades:\\n {}\\n\".format(df.property_type.unique()))\n",
    "print(\"Esta es una descripción general de las variables numéricas contenidas en el dataset:\\n\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METODOLOGÍA PARA ABORDAR EL PROBLEMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para garantizar un trabajo efectivo sobre estos datos, usaremos la metodología CRIPS-DM quien nos guiará en la respuesta\n",
    "cuestiones de interés sobre los datos que estamos estudiando. La metodología consta de los siguientes pasos:\n",
    "\n",
    "1. Entendimiento del negocio\n",
    "2. Entendimiento de los datos\n",
    "3. Preparación de datos\n",
    "4. Modelado de datos\n",
    "5. Evaluación de resultados\n",
    "6. Despliegue\n",
    "\n",
    "La etapa de despliegue usualmente involucra la disponibilidad de la solución analítica en un ambiente de producción, como apoyo a la toma de decisiones, esto está fuera del alcance del presente cuaderno, pero intentaremos abordar sistemáticamente las fases hasta donde nos sea posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entendimiento del negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es la cuestión principal que debemos resolver frente a los datos de propiedades inmobiliarias en colombia?. Esto naturalmente no tiene una única respuesta, sin embargo, para lograr un entendimiento de la situación podrían plantearse las siguientes cuestiones:\n",
    "\n",
    "- **Cuestion 1.** ¿Presenta el precio de las propiedades inmobiliarias diferencias significativas entre diferentes regiones del país?\n",
    "- **Cuestion 2.** ¿Hay una forma natural de agrupar propiedades según sus características?\n",
    "- **Cuestion 2.** ¿Cuáles variables de las que tenemos disponibles nos permiten predecir de mejor manera el precio de una propiedad y qué tanta precisión se logra?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entendimiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planteadas las cuestiones de interés vamos a dar una mirada más cercana a nuestros datos para ir respondiendo cada pregunta. En primer lugar revisaremos las variables que nos informan sobre la región donde se encuentran las propiedades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above are variables that python is treating as numeric variables, and therefore, we \n",
    "# could send them into our linear model blindly to predict the response\n",
    "# Let's take a quick look at our data first\n",
    "\n",
    "df.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), annot=True, fmt=\".2f\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can see that none of our variables appear to greatly correlated with salary\n",
    "# and we can see that if someone was given an expected salary question, they either\n",
    "# never answered the salary question or they were not given the salary question\n",
    "\n",
    "\n",
    "# We an still go ahead and make predictions using these variables as a reminder of the \n",
    "# scikit learn way of fitting models.  The process is similar to quickly fit models of \n",
    "# all types - usually a four step process of - instantiate, fit, predict, score\n",
    "# In most cases, we also will want to split data into training and test data to assure \n",
    "# we are not building models that overfit the data and do not extend well to new situations.\n",
    "\n",
    "X = df[['CareerSatisfaction', 'HoursPerWeek', 'JobSatisfaction', 'StackOverflowSatisfaction']]\n",
    "y = df['Salary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state=42)\n",
    "\n",
    "lm_model = LinearRegression(normalize=True) # Here you could set any hyperparameters of your model\n",
    "lm_model.fit(X_train, y_train) # If this model was to predict for new individuals, we probably would want\n",
    "               # worry about train/test splits and cross-validation, but for now I am most \n",
    "               # interested in finding a model that just fits all of the data well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Notice the above breaks because of the NaN values, so we either need to fill or remove them\n",
    "# Or we could write a conditional model that fits differently \n",
    "# depending on the values that are missing - we can see the nans based on the describe above\n",
    "df.shape\n",
    "\n",
    "\n",
    "#________ Video 1 through here on introduction to the data - could do a bit more EDA ________#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The easiest way to move onto a conclusion in a first pass is probably just with dropping\n",
    "\n",
    "num_vars = df[['Salary', 'CareerSatisfaction', 'HoursPerWeek', 'JobSatisfaction', 'StackOverflowSatisfaction']]\n",
    "df_dropna = num_vars.dropna(axis=0)\n",
    "\n",
    "X = df_dropna[['CareerSatisfaction', 'HoursPerWeek', 'JobSatisfaction', 'StackOverflowSatisfaction']]\n",
    "y = df_dropna['Salary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state=42)\n",
    "\n",
    "lm_model = LinearRegression(normalize=True) # Here you could set any hyperparameters of your model\n",
    "lm_model.fit(X_train, y_train) # If this model was to predict for new individuals, we probably would want\n",
    "               # worry about train/test splits and cross-validation, but for now I am most \n",
    "               # interested in finding a model that just fits all of the data well\n",
    "\n",
    "        \n",
    "y_test_preds = lm_model.predict(X_test) #We can then use our fitted model to predict the salary for each\n",
    "                                        #indvidual in our test set, and see how well these predictions\n",
    "                                        #match the truth.\n",
    "\n",
    "print(r2_score(y_test, y_test_preds)) #In this case we are predicting a continuous, numeric response.  Therefore, common\n",
    "print(mean_squared_error(y_test, y_test_preds)) #metrics to assess fit include Rsquared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whoop - we built a model that predicts... but we are missing by ALOT!\n",
    "# We can get a quick glimpse of how bad our predictions are...\n",
    "# This suggests that 3% of the variability in salaries can be explained by these variables...\n",
    "df_dropna.shape # But it also reduced our dataset to only 5338 rows \n",
    "                # ~20% of the original dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recorded from here up\n",
    "\n",
    "\n",
    "# Screencasts Remaining:\n",
    "1. Imputation - first results\n",
    "2. Categorical Variables - improved results, but what is happening?\n",
    "3. Combat Overfitting - one method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_vs_act = pd.DataFrame(np.hstack([y_test.values.reshape(y_test.size,1), y_test_preds.reshape(y_test.size,1)]))\n",
    "preds_vs_act.columns = ['actual', 'preds']\n",
    "preds_vs_act['diff'] = preds_vs_act['actual'] - preds_vs_act['preds']\n",
    "preds_vs_act.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We can plot how far our predictions are from the actual values compaired to the\n",
    "### predicted values - you can see that it isn't uncommon for us to miss salaries by\n",
    "### 150000 and the overpredictions tend to be much worse than the underpredictions\n",
    "### THere also appears to be a trend where our differences decrease as the predicted\n",
    "### values increase on the test data.\n",
    "\n",
    "plt.plot(preds_vs_act['preds'], preds_vs_act['diff'], 'bo');\n",
    "plt.xlabel('predicted');\n",
    "plt.ylabel('difference');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#______Video 2 ____Our First Modeling Attempt (Mark all the bad things)________#\n",
    "\n",
    "\n",
    "\n",
    "### There are tons of downfalls already - our predictions are pretty poor, we have predictions\n",
    "### for only 20% of the total values that actually hold salaries, and we are only using \n",
    "### quantitative variables to predict.\n",
    "\n",
    "### Given how bad the predictions are, we might not hurt anything by just filling the missing \n",
    "### values to make more predictions.\n",
    "\n",
    "#Here we fill on the column means\n",
    "df_fillna = num_vars.apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "\n",
    "X = df_fillna[['CareerSatisfaction', 'HoursPerWeek', 'JobSatisfaction', 'StackOverflowSatisfaction']]\n",
    "y = df_fillna['Salary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state=42)\n",
    "\n",
    "lm_model = LinearRegression(normalize=True) # Here you could set any hyperparameters of your model\n",
    "lm_model.fit(X_train, y_train) # If this model was to predict for new individuals, we probably would want\n",
    "               # worry about train/test splits and cross-validation, but for now I am most \n",
    "               # interested in finding a model that just fits all of the data well\n",
    "\n",
    "        \n",
    "y_test_preds = lm_model.predict(X_test) #We can then use our fitted model to predict the salary for each\n",
    "                                        #indvidual in our test set, and see how well these predictions\n",
    "                                        #match the truth.\n",
    "\n",
    "print(r2_score(y_test, y_test_preds)) #In this case we are predicting a continuous, numeric response.  Therefore, common\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we can predict on everything, but our predictions are even worse!\n",
    "\n",
    "preds_vs_act = pd.DataFrame(np.hstack([y_test.values.reshape(y_test.size,1), y_test_preds.reshape(y_test.size,1)]))\n",
    "preds_vs_act.columns = ['actual', 'preds']\n",
    "preds_vs_act['diff'] = preds_vs_act['actual'] - preds_vs_act['preds']\n",
    "preds_vs_act.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(preds_vs_act['preds'], preds_vs_act['diff'], 'bo');\n",
    "plt.xlabel('predicted');\n",
    "plt.ylabel('difference');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(preds_vs_act['preds'], preds_vs_act['actual'], 'bo');\n",
    "plt.xlabel('predicted');\n",
    "plt.ylabel('actual'); #This looks less compelling that we are predicting well...\n",
    "# I also think I found the mean amount...which aren't real 'actual' salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some strange line here - probably because we filled in our average for everything\n",
    "### Which was actually data leakage.  We shouldn't have done this at all. We would likely\n",
    "### Have to use the mean of the old data to fill in the missing of the future data...\n",
    "\n",
    "### But this does depend a bit - if on future homes, you will have the x-variables before\n",
    "### having to predict, this really isn't data leakage, as you would have the abiltiy to update\n",
    "### the inputed means with each new individual in your dataset.\n",
    "\n",
    "### Really the values that have the mean value for the salary should be dropped - because\n",
    "### those are not true salaries.\n",
    "\n",
    "df_fillna = df_fillna.drop(df_fillna[df_fillna['Salary'] == np.mean(df['Salary'])].index)\n",
    "df_fillna.shape # that's better. we only have this many non-null salaries in our original dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below you can fit a new model with the missing salaries removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_fillna[['CareerSatisfaction', 'HoursPerWeek', 'JobSatisfaction', 'StackOverflowSatisfaction']]\n",
    "y = df_fillna['Salary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state=42)\n",
    "\n",
    "lm_model = LinearRegression(normalize=True) # Here you could set any hyperparameters of your model\n",
    "lm_model.fit(X_train, y_train) # If this model was to predict for new individuals, we probably would want\n",
    "               # worry about train/test splits and cross-validation, but for now I am most \n",
    "               # interested in finding a model that just fits all of the data well\n",
    "\n",
    "        \n",
    "y_test_preds = lm_model.predict(X_test) #We can then use our fitted model to predict the salary for each\n",
    "                                        #indvidual in our test set, and see how well these predictions\n",
    "                                        #match the truth.\n",
    "\n",
    "print(r2_score(y_test, y_test_preds)) #In this case we are predicting a continuous, numeric response.  Therefore, common\n",
    "print(mean_squared_error(y_test, y_test_preds)) #metrics to assess fit include Rsquared and MSE.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Stop Video 2\n",
    "\n",
    "\n",
    "\n",
    "### Now we can predict on everything, but our predictions are even worse!\n",
    "\n",
    "preds_vs_act = pd.DataFrame(np.hstack([y_test.values.reshape(y_test.size,1), y_test_preds.reshape(y_test.size,1)]))\n",
    "preds_vs_act.columns = ['actual', 'preds']\n",
    "preds_vs_act['diff'] = preds_vs_act['actual'] - preds_vs_act['preds']\n",
    "preds_vs_act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(preds_vs_act['preds'], preds_vs_act['diff'], 'bo');\n",
    "plt.xlabel('predicted');\n",
    "plt.ylabel('difference');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### When we see fan like shapes in the residual plots like this - it often suggests\n",
    "### we might make better predictions on the log of the response\n",
    "\n",
    "plt.plot(preds_vs_act['preds'], preds_vs_act['actual'], 'bo');\n",
    "plt.xlabel('predicted');\n",
    "plt.ylabel('actual'); #there appears to be a slight positive trend like we would want to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#______Video 3 Fill in Missing values with the mean - why this is bad_______#\n",
    "\n",
    "\n",
    "### Let's see how we might be able to use categorical variables in our models.\n",
    "### Though you might try to do something smart to reduce the feature space of your\n",
    "### x-matrix (like find curved relationships that exist in salary comparing across categories).\n",
    "### It is probably easier to just blindly encode all of the categorical variables as dummy\n",
    "### variables in our models.\n",
    "\n",
    "cat_vars_int = df.select_dtypes(include=['object']).copy().columns\n",
    "# http://pbpython.com/categorical-encoding.html\n",
    "\n",
    "len(cat_vars_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now that we have a list of all the dummy variables we might be interested in... \n",
    "### Let's dummy code them, so that we can use them in our machine learning models\n",
    "### you can do this with pandas (get dummies) or with sklearn (one hot encoding)\n",
    "### Feel free to use whatever you are comfortable with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in  cat_vars_int:\n",
    "    # for each cat add dummy var, drop original column\n",
    "    df = pd.concat([df.drop(var, axis=1), pd.get_dummies(df[var], prefix=var, prefix_sep='_', drop_first=True)], axis=1)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Because we have more rows than number of variables, it is actually possible\n",
    "### for us to build a model that uses all of the columns to predict the response...\n",
    "### Whether this is actually a good idea or not is up for debate - let's maybe\n",
    "### choose some variables that seem like they might be related to salary and go from there.\n",
    "\n",
    "### You can also see that the nulls are still dropped after dummy encoding, which means\n",
    "### we will again need to figure out what to do with rows where those values are null.\n",
    "### It might be okay to just use the mode of the dataset to fill in those values - though\n",
    "### in reality, a lack of answer is maybe an indication that your answer is different \n",
    "### from the group and therefore, you didn't want to answer the question.\n",
    "\n",
    "### We know there are 12891 non-NaN salaries to predict based on the previous model - so we\n",
    "### want to make sure we can predict all of these salaries with our new model as well, but now\n",
    "### unlike the 5 columns we had to choose from before we have more than 40,000 to choose from.\n",
    "### This could be a great place for some PCA or PLS, but I would like to try and keep \n",
    "### the interpretability of the features as much as possible... so I am just going to\n",
    "### use the original features. \n",
    "\n",
    "### We could try even adding interactions or other combinations of these features, but again\n",
    "### this would make our features less interpretable. So you have to weigh the pros and cons\n",
    "### of adding these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.concat([df, df_fillna], axis=1, join='inner')\n",
    "df_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['Salary'].head()['Salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_result.iloc[:,~df_result.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we have no duplicated columns, we can focus on which of our new columns (and the \n",
    "### previously used columns) we would like to use to try and predict the response.  We might\n",
    "### just go based on intuition, or we could try to find the variables that are most correlated\n",
    "### Don't get too high of hopes - having a quant variable correlated with a 1-0 variable\n",
    "### is not really what correlation coefficients are designed to detect.  They are meant\n",
    "### to find linear relationships between quant variables. Though correlations are not built for\n",
    "### finding these relations - they can still give a sense of which variables are best related\n",
    "\n",
    "\n",
    "### Actually if you try to build the correlation matrix... it might run for a long time, and\n",
    "### not be very legible anyway... Let's just fit some stuff that seems interesting \n",
    "### and intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Given how many columns we have to use - let's just drop all of the columns that have any\n",
    "### missing values\n",
    "\n",
    "df_result = df_result.dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.shape # which is only 6, sooo that kind of sucks at narrowing down this mess..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_result['Salary']\n",
    "X = df_result.drop(['Respondent', 'Salary'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state=42)\n",
    "\n",
    "#lm_model = LinearRegression(normalize=True) # Here you could set any hyperparameters of your model\n",
    "#lm_model.fit(X_train, y_train) # If this model was to predict for new individuals, we probably would want\n",
    "               # worry about train/test splits and cross-validation, but for now I am most \n",
    "               # interested in finding a model that just fits all of the data well\n",
    "\n",
    "        \n",
    "#y_test_preds = lm_model.predict(X_test) #We can then use our fitted model to predict the salary for each\n",
    "                                        #indvidual in our test set, and see how well these predictions\n",
    "                                        #match the truth.\n",
    "\n",
    "#print(r2_score(y_test, y_test_preds)) #In this case we are predicting a continuous, numeric response.  Therefore, common\n",
    "#print(mean_squared_error(y_test, y_test_preds)) #metrics to assess fit include Rsquared and MSE.  \n",
    "## Filling in the missing values does appear to have helped based on a preliminary check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(r2_score(y_train, lm_model.predict(X_train)))\n",
    "#print(mean_squared_error(y_train, lm_model.predict(X_train))) # What does this mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combat the overfitting we have a number of options, but one way that would also reduce our run time would be to remove columns from our dataframe.  You will notice that sklearn does not provide pvals back for our coefficients, but it performs ridge regression by default.  So, therefore, we can consider that columns that have larger coefficients are also more useful for predicting our response variable.  How large is large enough to consider keeping? Well, that is a great question, and I also don't have a great answer...  We can try some stuff and see what works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can also run cross-validation and aggregate our results to combat the overfitting we saw earlier using this reduced X matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could deal with these rare events in different ways - you could consider them as great predictors\n",
    "# I am going to remove them - as I feel like they are likely not that indicative of other individuals\n",
    "# I want to find overriding truths about the individuals who receive particular salaries.\n",
    "# So, let's only consider columns where there are more than 1000 of the level of interest in the column.\n",
    "\n",
    "reduce_X = X.iloc[:, np.where((X.sum() > 10) == True)[0]]\n",
    "reduce_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = .30, random_state=42)\n",
    "\n",
    "lm_model = LinearRegression(normalize=True) # Here you could set any hyperparameters of your model\n",
    "lm_model.fit(X_train, y_train) # If this model was to predict for new individuals, we probably would want\n",
    "               # worry about train/test splits and cross-validation, but for now I am most \n",
    "               # interested in finding a model that just fits all of the data well\n",
    "\n",
    "        \n",
    "y_test_preds = lm_model.predict(X_test) #We can then use our fitted model to predict the salary for each\n",
    "                                        #indvidual in our test set, and see how well these predictions\n",
    "                                        #match the truth.\n",
    "\n",
    "print(r2_score(y_test, y_test_preds)) #In this case we are predicting a continuous, numeric response.  Therefore, common\n",
    "print(mean_squared_error(y_test, y_test_preds)) #metrics to assess fit include Rsquared and MSE.  \n",
    "## Filling in the missing values does appear to have helped based on a preliminary check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_train, lm_model.predict(X_train))) #In this case we are predicting a continuous, numeric response.  Therefore, common\n",
    "print(mean_squared_error(y_train, lm_model.predict(X_train))) #metrics to assess fit include Rsquared and MSE.  \n",
    "## Filling in the missing values does appear to have helped based on a preliminary check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's see what be the best number of features to use based on the test set performance\n",
    "def find_optimal_lm_mod(X, y, cutoffs, test_size = .30, random_state=42, plot=True):\n",
    "    '''\n",
    "    INPUT\n",
    "    X - pandas dataframe, X matrix\n",
    "    y - pandas dataframe, response variable\n",
    "    cutoffs - list of ints, cutoff for number of non-zero values in dummy categorical vars\n",
    "    test_size - float between 0 and 1, default 0.3, determines the proportion of data as test data\n",
    "    random_state - int, default 42, controls random state for train_test_split\n",
    "    plot - boolean, default 0.3, True to plot result\n",
    "    \n",
    "    OUTPUT\n",
    "    r2_scores_test - list of floats of r2 scores on the test data\n",
    "    r2_scores_train - list of floats of r2 scores on the train data\n",
    "    lm_model - model object from sklearn\n",
    "    X_train, X_test, y_train, y_test - output from sklearn train test split used for optimal model\n",
    "    '''\n",
    "    r2_scores_test, r2_scores_train, num_feats, results = [], [], [], dict()\n",
    "    for cutoff in cutoffs:\n",
    "        \n",
    "        #reduce X matrix\n",
    "        reduce_X = X.iloc[:, np.where((X.sum() > cutoff) == True)[0]]\n",
    "        num_feats.append(reduce_X.shape[1])\n",
    "\n",
    "        #split the data into train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = test_size, random_state=random_state)\n",
    "\n",
    "        #fit the model and obtain pred response\n",
    "        lm_model = LinearRegression(normalize=True) \n",
    "        lm_model.fit(X_train, y_train)\n",
    "        y_test_preds = lm_model.predict(X_test)\n",
    "        y_train_preds = lm_model.predict(X_train)\n",
    "        \n",
    "        #append the r2 value from the test set\n",
    "        r2_scores_test.append(r2_score(y_test, y_test_preds))\n",
    "        r2_scores_train.append(r2_score(y_train, y_train_preds))\n",
    "        results[str(cutoff)] = r2_score(y_test, y_test_preds)\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(num_feats, r2_scores_test, label=\"Test\", alpha=.5)\n",
    "        plt.plot(num_feats, r2_scores_train, label=\"Train\", alpha=.5)\n",
    "        plt.xlabel('Number of Features')\n",
    "        plt.ylabel('Rsquared')\n",
    "        plt.title('Rsquared by Number of Features')\n",
    "        plt.legend(loc=1)\n",
    "        plt.show()\n",
    "        \n",
    "    best_cutoff = max(results, key=results.get)\n",
    "    \n",
    "    #reduce X matrix\n",
    "    reduce_X = X.iloc[:, np.where((X.sum() > int(best_cutoff)) == True)[0]]\n",
    "    num_feats.append(reduce_X.shape[1])\n",
    "\n",
    "    #split the data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = test_size, random_state=random_state)\n",
    "\n",
    "    #fit the model\n",
    "    lm_model = LinearRegression(normalize=True) \n",
    "    lm_model.fit(X_train, y_train)\n",
    "        \n",
    "    return r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = [5000, 3500, 2500, 1000, 100, 50, 30, 20, 10, 5]\n",
    "r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test = find_optimal_lm_mod(X, y, cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#______Video 4 Creating Dummy Variables & Other Alternatives for Categorical Variables____#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Now that we have the best model in terms of the r2 on the test data, we can use this model to see which features\n",
    "### appear to be most important, and what impact they have on salary.\n",
    "\n",
    "X_train.shape # we have 1081 features in the optimal model - let's look at some of them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = lm_model.predict(X_test)\n",
    "\n",
    "preds_vs_act = pd.DataFrame(np.hstack([y_test.values.reshape(y_test.size,1), y_test_preds.reshape(y_test.size,1)]))\n",
    "preds_vs_act.columns = ['actual', 'preds']\n",
    "preds_vs_act['diff'] = preds_vs_act['actual'] - preds_vs_act['preds']\n",
    "\n",
    "plt.plot(preds_vs_act['preds'], preds_vs_act['diff'], 'bo');\n",
    "plt.xlabel('predicted');\n",
    "plt.ylabel('difference');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(preds_vs_act['preds'], preds_vs_act['actual'], 'bo');\n",
    "plt.xlabel('predicted');\n",
    "plt.ylabel('actual'); #there appears to be a slight positive trend like we would want to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df = pd.DataFrame()\n",
    "\n",
    "coefs_df['est_int'] = X_train.columns\n",
    "coefs_df['coefs'] = lm_model.coef_\n",
    "coefs_df['abs_coefs'] = np.abs(lm_model.coef_)\n",
    "\n",
    "coefs_df.sort_values('abs_coefs', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, sum(X_train['Professional_Professional developer'])\n",
    "\n",
    "\n",
    "#_____Video 7 Interpretting the results_____#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#____Video 8 - Ensemble Models______#\n",
    "\n",
    "### One of the best out of the box methods for supervised machine learning\n",
    "### is known as the RandomForest - let's see if we can use this model to outperform\n",
    "### The linear model from earlier.\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "### Let's see what be the best number of features to use based on the test set performance\n",
    "def find_optimal_rf_mod(X, y, cutoffs, test_size = .30, random_state=42, plot=True):\n",
    "    '''\n",
    "    INPUT\n",
    "    X - pandas dataframe, X matrix\n",
    "    y - pandas dataframe, response variable\n",
    "    cutoffs - list of ints, cutoff for number of non-zero values in dummy categorical vars\n",
    "    test_size - float between 0 and 1, default 0.3, determines the proportion of data as test data\n",
    "    random_state - int, default 42, controls random state for train_test_split\n",
    "    plot - boolean, default 0.3, True to plot result\n",
    "    kwargs - include the arguments you want to pass to the rf model\n",
    "    \n",
    "    OUTPUT\n",
    "    r2_scores_test - list of floats of r2 scores on the test data\n",
    "    r2_scores_train - list of floats of r2 scores on the train data\n",
    "    rf_model - model object from sklearn\n",
    "    X_train, X_test, y_train, y_test - output from sklearn train test split used for optimal model\n",
    "    '''\n",
    "    r2_scores_test, r2_scores_train, num_feats, results = [], [], [], dict()\n",
    "    for cutoff in cutoffs:\n",
    "        \n",
    "        #reduce X matrix\n",
    "        reduce_X = X.iloc[:, np.where((X.sum() > cutoff) == True)[0]]\n",
    "        num_feats.append(reduce_X.shape[1])\n",
    "\n",
    "        #split the data into train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = test_size, random_state=random_state)\n",
    "\n",
    "        #fit the model and obtain pred response\n",
    "\n",
    "        rf_model = RandomForestRegressor()  #no normalizing here, but could tune other hyperparameters\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_test_preds = rf_model.predict(X_test)\n",
    "        y_train_preds = rf_model.predict(X_train)\n",
    "        \n",
    "        #append the r2 value from the test set\n",
    "        r2_scores_test.append(r2_score(y_test, y_test_preds))\n",
    "        r2_scores_train.append(r2_score(y_train, y_train_preds))\n",
    "        results[str(cutoff)] = r2_score(y_test, y_test_preds)\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(num_feats, r2_scores_test, label=\"Test\", alpha=.5)\n",
    "        plt.plot(num_feats, r2_scores_train, label=\"Train\", alpha=.5)\n",
    "        plt.xlabel('Number of Features')\n",
    "        plt.ylabel('Rsquared')\n",
    "        plt.title('Rsquared by Number of Features')\n",
    "        plt.legend(loc=1)\n",
    "        plt.show()\n",
    "        \n",
    "    best_cutoff = max(results, key=results.get)\n",
    "    \n",
    "    #reduce X matrix\n",
    "    reduce_X = X.iloc[:, np.where((X.sum() > int(best_cutoff)) == True)[0]]\n",
    "    num_feats.append(reduce_X.shape[1])\n",
    "\n",
    "    #split the data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = test_size, random_state=random_state)\n",
    "\n",
    "    #fit the model\n",
    "    rf_model = RandomForestRegressor() \n",
    "    rf_model.fit(X_train, y_train)\n",
    "        \n",
    "    return r2_scores_test, r2_scores_train, rf_model, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = [5000, 3500, 2500, 1000, 100, 50, 30, 20, 10, 5]\n",
    "r2_test, r2_train, rf_model, X_train, X_test, y_train, y_test = find_optimal_rf_mod(X, y, cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = rf_model.predict(X_test)\n",
    "\n",
    "preds_vs_act = pd.DataFrame(np.hstack([y_test.values.reshape(y_test.size,1), y_test_preds.reshape(y_test.size,1)]))\n",
    "preds_vs_act.columns = ['actual', 'preds']\n",
    "preds_vs_act['diff'] = preds_vs_act['actual'] - preds_vs_act['preds']\n",
    "\n",
    "plt.plot(preds_vs_act['preds'], preds_vs_act['diff'], 'bo');\n",
    "plt.xlabel('predicted');\n",
    "plt.ylabel('difference');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks like this overfits quite a bit... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "### Let's see what be the best number of features to use based on the test set performance\n",
    "def find_optimal_rf_mod(X, y, cutoffs, test_size = .30, random_state=42, plot=True, param_grid=None):\n",
    "    '''\n",
    "    INPUT\n",
    "    X - pandas dataframe, X matrix\n",
    "    y - pandas dataframe, response variable\n",
    "    cutoffs - list of ints, cutoff for number of non-zero values in dummy categorical vars\n",
    "    test_size - float between 0 and 1, default 0.3, determines the proportion of data as test data\n",
    "    random_state - int, default 42, controls random state for train_test_split\n",
    "    plot - boolean, default 0.3, True to plot result\n",
    "    kwargs - include the arguments you want to pass to the rf model\n",
    "    \n",
    "    OUTPUT\n",
    "    r2_scores_test - list of floats of r2 scores on the test data\n",
    "    r2_scores_train - list of floats of r2 scores on the train data\n",
    "    rf_model - model object from sklearn\n",
    "    X_train, X_test, y_train, y_test - output from sklearn train test split used for optimal model\n",
    "    '''\n",
    "\n",
    "    r2_scores_test, r2_scores_train, num_feats, results = [], [], [], dict()\n",
    "    for cutoff in cutoffs:\n",
    "\n",
    "        #reduce X matrix\n",
    "        reduce_X = X.iloc[:, np.where((X.sum() > cutoff) == True)[0]]\n",
    "        num_feats.append(reduce_X.shape[1])\n",
    "\n",
    "        #split the data into train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = test_size, random_state=random_state)\n",
    "\n",
    "        #fit the model and obtain pred response\n",
    "        if param_grid==None:\n",
    "            rf_model = RandomForestRegressor()  #no normalizing here, but could tune other hyperparameters\n",
    "\n",
    "        else:\n",
    "            rf_inst = RandomForestRegressor(n_jobs=-1, verbose=1)\n",
    "            rf_model = GridSearchCV(rf_inst, param_grid, n_jobs=-1) \n",
    "            \n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_test_preds = rf_model.predict(X_test)\n",
    "        y_train_preds = rf_model.predict(X_train)\n",
    "\n",
    "        #append the r2 value from the test set\n",
    "        r2_scores_test.append(r2_score(y_test, y_test_preds))\n",
    "        r2_scores_train.append(r2_score(y_train, y_train_preds))\n",
    "        results[str(cutoff)] = r2_score(y_test, y_test_preds)\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(num_feats, r2_scores_test, label=\"Test\", alpha=.5)\n",
    "        plt.plot(num_feats, r2_scores_train, label=\"Train\", alpha=.5)\n",
    "        plt.xlabel('Number of Features')\n",
    "        plt.ylabel('Rsquared')\n",
    "        plt.title('Rsquared by Number of Features')\n",
    "        plt.legend(loc=1)\n",
    "        plt.show()\n",
    "        \n",
    "    best_cutoff = max(results, key=results.get)\n",
    "\n",
    "    #reduce X matrix\n",
    "    reduce_X = X.iloc[:, np.where((X.sum() > int(best_cutoff)) == True)[0]]\n",
    "    num_feats.append(reduce_X.shape[1])\n",
    "\n",
    "    #split the data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = test_size, random_state=random_state)\n",
    "\n",
    "    #fit the model\n",
    "    if param_grid==None:\n",
    "        rf_model = RandomForestRegressor()  #no normalizing here, but could tune other hyperparameters\n",
    "\n",
    "    else:\n",
    "        rf_inst = RandomForestRegressor(n_jobs=-1, verbose=1)\n",
    "        rf_model = GridSearchCV(rf_inst, param_grid, n_jobs=-1) \n",
    "    rf_model.fit(X_train, y_train)\n",
    "     \n",
    "    return r2_scores_test, r2_scores_train, rf_model, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = [5000, 3500, 2500, 1000, 100, 50, 30, 20, 10, 5]\n",
    "params = {'n_estimators': [10, 100, 1000], 'max_depth': [1, 5, 10, 100]}\n",
    "r2_test, r2_train, rf_model, X_train, X_test, y_train, y_test = find_optimal_rf_mod(X, y, cutoffs, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
